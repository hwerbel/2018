---
title: ''
feature_text: |
  ## P-RECS 2018
  First International Workshop on Practical Reproducible Evaluation of 
  Computer Systems.

  In conjunction with [HPDC'18](https://hpdc.org/2018/). In 
  cooperation with (pending):

  ![[SIGHPC](http://www.sighpc.org)](/assets/SIGhpc_logo_small.png)
feature_image: ""
excerpt: "This workshop is going to be fun."
---


Independent evaluation of experimental results in the area of computer 
and networking systems is a challenging task. Recreating the 
environment where an experiment originally ran is commonly considered 
impractical or even impossible. This workshop will focus heavily on 
practical, actionable aspects of reproducibility in broad areas of 
computational science and data exploration, with special emphasis on 
issues in which community collaboration can be essential for adopting 
novel methodologies, techniques and frameworks aimed at addressing 
some of the challenges we face today. The workshop will bring together 
researchers and experts to share experiences and advance the state of 
the art in the reproducible evaluation of computer systems, featuring 
contributed papers and invited talks.

## Topics

We expect submissions from topics such as, but not limited to:

  * Experiment dependency management.
  * Software citation and persistence.
  * Data versioning and preservation.
  * Provenance of data-intensive experiments.
  * Tools and techniques for incorporating provenance into publications.
  * Automated experiment execution and validation.
  * Experiment portability for code, performance, and related metrics.
  * Experiment discoverability for re-use.
  * Cost-benefit analysis frameworks for reproducibility.
  * Usability and adaptability of reproducibility frameworks into already-established domain-specific tools.
  * Long-term artifact archiving for future reproducibility.
  * Frameworks for sociological constructs to incentivize paradigm shifts.
  * Policies around publication of articles/software.
  * Blinding and selecting artifacts for review while maintaining history.
  * Reproducibility-aware computational infrastructure.

## Submission

There will be two categories of submissions:

  * **Position papers**. These will be vision papers whose goal is to 
    propose solutions (or scope the work that needs to be done) to 
    address some of the issues outlined above. We hope that a research 
    agenda comes out of this and that we can create a community that 
    meets yearly to report on our status in addressing these problems.

  * **Experience papers**. We will encourage the community to make use 
    of an automated service (see subsection below). Based on their 
    experience in automating one or more experiments, the committee 
    will look for submissions reporting on their experience: what 
    worked? What aspects of experiment automation and validation are 
    hard in their domain? What can be done to improve the tooling for 
    their domain?

### Automated Execution and Validation Server

We have an instance of Jenkins running at <http://ci.falsifiable.us>, 
maintained by members of the [Systems Research Lab 
(SRL)](https://systemslab.github.io) at UC Santa Cruz. This service 
allows researchers and students to automate the execution and 
validation of experimentation pipelines. See instructions on how to 
create an account and use this service 
[here](http://popper.readthedocs.io/en/latest/ci/jenkins.html#ci-falsifiable-us).

> **NOTE**: Using the server at <http://ci.falsifiable.us> is not 
> obligatory for submissions to be considered for the Experience Paper 
> category. Instead, we will require authors to provide a URL to the 
> service they use (e.g., TravisCI) so reviewers can verify that there 
> is one or more automated pipelines associated to the submission.

## Important Dates

  * Submissions due: April 1, 2018
  * Acceptance notification: April 20, 2018
  * Camera-ready paper submission: May 10, 2018
  * Workshop: June 11, 2018

## Organizers

  * [Ivo Jimenez](https://cs.ucsc.edu/~ivo), UC Santa Cruz
  * [Carlos Maltzahn](https://users.soe.ucsc.edu/~carlosm/), UC Santa 
    Cruz
  * [Jay Lofstead](www.lofstead.org), Sandia National Laboratories

## Program Committee

  * Michela Taufer, University of Delaware
  * Victoria Stodden, UIUC
  * Torsten Hoefler, ETH Zürich
  * Reed Milewicz, Sandia National Laboratories
  * Anja Feldmann, TU Berlin
  * Dan Katz, NCSA
  * Michael Zink, UMass Amherst
  * Todd Gamblin, LLNL
  * Arnaud Legrand, Bâtiment IMAG
  * Violet R. Syrotiuk, ASU
  * Ignacio Laguna, LLNL
  * Divyashri Bhat, UMass Amherst
  * Kate Keahey, Argonne National Lab / ChameleonCloud
  * Robert Ricci, University of Utah / CloudLab
  * Neil Chue Hong, Software Sustainability Institute / University of Edinburgh, UK
  * Mike Heroux, Sandia National Laboratories

## Contact

Please address workshop questions to <ivo@cs.ucsc.edu>.
